<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>regression, on Udeshya</title><link>https://udeshyadhungana.com.np/tags/regression/</link><description>Recent content in regression, on Udeshya</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Tue, 04 May 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://udeshyadhungana.com.np/tags/regression/index.xml" rel="self" type="application/rss+xml"/><item><title>Linear Regression</title><link>https://udeshyadhungana.com.np/posts/2021-05-04-linear-regression/</link><pubDate>Tue, 04 May 2021 00:00:00 +0000</pubDate><guid>https://udeshyadhungana.com.np/posts/2021-05-04-linear-regression/</guid><description>Hello. Today I want to write about Linear Regression. It is basically the &amp;#34;Hello, World&amp;#34; program of Machine Learning. It is used to model the relationship between one or more inputs and a single output. Its application ranges from engineering to business. It is a process of learning from data. It falls under supervised learning category of Maching Learning. Regarding the algorithm, we have a set of inputs ($X$) and their corresponding outputs ($Y$).</description></item></channel></rss>